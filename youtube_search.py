#!/usr/bin/python
# -*- coding: utf-8 -*-

"""
youtube_search.py

searches for YouTube videos with no views

The Google YouTube Data API comes with certain restrictions that prevents
from directly searching for content with no views. Namely:
  1) one cannot use view count as a search parameter, and
  2) any search query will return at most 500 results.

This script uses a brute force type approach by performing the search to a
bunch of search terms and saves the results with zero views to a file.

The search terms are read from a dynamic index file initialized with ~ 71 000
words. Additional search terms are generated by combining a smaller set of
common words. The words are read in groups of 50, the script performs a brute
force YouTube query on them on stores links for items with no views.
"""


import json
import random
import argparse
import datetime
import logging
import os.path

from apiclient.discovery import build
from apiclient.errors import HttpError



# Setup a logger and attach a formatter and a file handler to it.
log_formatter = logging.Formatter("%(asctime)s %(levelname)s %(message)s")
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Attach a FileHandler to point the output to a file
file_handler = logging.FileHandler("./search.log")
file_handler.setFormatter(log_formatter)
logger.addHandler(file_handler)

# ...and a StreamHandler to also send output to stderr
console_handler = logging.StreamHandler()
console_handler.setFormatter(log_formatter)
logger.addHandler(console_handler)




class YouTubeExplorer:
  """Performs YouTube queries."""

  def __init__(self):
    with open("./keys.json") as f:
      keys = json.load(f)

    GOOGLE_API_KEY = keys["GOOGLE_API_KEY"]
    YOUTUBE_API_SERVICE_NAME = "youtube"
    YOUTUBE_API_VERSION = "v3"
    self.youtube = build(YOUTUBE_API_SERVICE_NAME, YOUTUBE_API_VERSION, developerKey = GOOGLE_API_KEY)

  def query_youtube(self, **kwargs):
    """Perform a single YouTube query using given search parameters. Order results by viewcount and
    return the final page of the result set.
    Arg:
      kwargs: parameters to pass to youtube.search().list()
    Return:
      the final page of the results as dicts of items returned by YouTube API
      or None if no results.
    """
    request = self.youtube.search().list(
      q = kwargs["q"],
      part = "id,snippet",
      publishedBefore = kwargs["before"],
      publishedAfter = kwargs["after"],
      relevanceLanguage = "en",
      maxResults = 50,
      order = "viewCount",
      type = "video"
    )

    # fetch the next page until no more pages or no items in current page.
    response = None
    while request is not None:
      prev_response = response
      response = request.execute()
      request = self.youtube.search().list_next(request, response)

      # If the current response doesn't contain any items,
      # return the previous response (possibly None).
      if not response["items"]:
        return prev_response

    return response

  def get_stats(self, vid_id):
    """Get view count and upload date for a given video.
    Arg:
      vid_id (string): a Youtube video id
    Return:
      a dict of the view count and upload date
    """
    stats = self.youtube.videos().list(
      part = "statistics,snippet",
      id = vid_id
    ).execute()

    viewcount = stats["items"][0]["statistics"]["viewCount"]
    date = stats["items"][0]["snippet"]["publishedAt"]

    # date is in ISO format (YYYY-MM-DD), reformat to DD.MM.YYYY
    d = date[8:10]
    m = date[5:7]
    y = date[0:4]
    date = d + "." + m + "." + y

    return { "views": viewcount, "upload_date": date }


class YouTubeCrawler:

  def __init__(self, base = "data/"):
    self.index = base + "index.json"

  def zero_search(self, n = 100, random_window = False):
    """Perform youtube_query() on n serach terms with:
      * n/2 items read randomly from search_terms.json, and
      * n/2 items generated randomly by combining words in common.txt.
    Check for videos with no views and return as a list.
    Args:
      n (int): total number of search queries to perform
      random_window (boolean): whether a year long time window should be randomly generated
        as an additional search parameter. If False, the search window will be set to match
        any videos published at least a year ago from today
    Return:
      a list of {title, url, views, published} dictionaries
    """
    zero_views = []

    # Get the first n/2 search terms from search_terms.json and another n/2 by
    # combining word from common.txt.
    next_slice = self.get_next_slice(n/2)
    randomized_search_terms = self.generate_random_search_terms(n/2, 2)

    youtube_explorer = YouTubeExplorer()

    # perform a youtube query for each search term
    for search_term in next_slice + randomized_search_terms:
      search_term = search_term.encode("utf8") # encode before network I/O
      query_params = self.format_search_params(search_term)  # generates a new timewindow for each searchterm!
      result_page = youtube_explorer.query_youtube(query_params) # result is either None or a dict containing a key for list of videos
      if result_page:
        stats = self.parse_youtube_response(result_page)
        zero_views.extend(stats)

        # Print a checkmark if this search term provided at least one result.
        if stats:
          print search_term + " âœ“"
        else:
          print search_term


    self.logger.info("%s new links detected", len(zero_views))
    return zero_views

  def parse_youtube_response(response):
    """Parse a response page from the API for videos with no views.
    Arg:
      response (dict): the API response to a search query
    Return:
      a list of items with no views. Each item is a dict of {title, url, views, date}
    """
    valid = []
    for item in reversed(response["items"]):  # loop backwards so item with least views is first
      vid_id = item["id"]["videoId"]
      stats = self.get_stats(vid_id)
      views = int(stats["views"])
      live = item["snippet"]["liveBroadcastContent"]
      url = "https://www.youtube.com/watch?v=" + vid_id

      # return as soon as we find a video which has views
      if views:
        return

      # skip videos with live broadcast content: these often lead to missing videos with a "content not available" notification
      if live == "none":
        title = item["snippet"]["title"]
        view_count = stats["views"]
        upload_date = stats["upload_date"]

        # valid zero-view item: wrap as a dict and store
        data = {"title": title, "url": url, "views": view_count, "date": upload_date}
        valid.append(data)


      # No views, but has live content: print for logging purposes.
      else:
        self.logger.info("liveBroadcastContent: %s", live)

    return valid

  def get_next_slice(self, n):
    """Pop and return a random selection of n items from the index. Recreates
    the index if there are < n items left."""
    with open(self.index) as f:
      index = json.load(f)

    # shuffle the index to get n random elements from the head
    random.shuffle(index)
    head = index[:n]
    tail = index[n:] # empty if < n items left in the index

    if not tail:
      self.create_index()

    # store the rest back to file
    with open(self.index, "w") as f:
      json.dump(tail)

    return head

  def generate_random_search_terms(self, n, word_count = 1):
    """Generate n random search terms by combining words from common.txt.
    Arg:
      n (int): number of search terms to generate
      word_count (int): number of words each search term should consist of
    Return:
      a list of search terms
    """
    with open("./common.txt") as f:
      lines = [line.rstrip("\n") for line in f]

    search_terms = []
    for i in range(n):
      sample = random.sample(lines, word_count)
      search_term = " ".join(sample)

      if search_term not in search_terms:
        search_terms.append(search_term)

    return search_terms

  def create_index(self):
    """Create a json index file from dict.txt"""
    with open("./dict.txt") as f:
      search_terms = f.read().splitlines()

    with open(self.index, "w") as f:
      json.dump(search_terms, f)

  def format_search_params(self, q, before = None):
    """Format a dict of query parameters to pass to the youtube query API. The parameters include
    the search term and the 'before' and 'after' values. 'after' is set to a year backwards from 'before' while
    'before' is either given as a paramter or randomly set to somewhere between a year ago and 1.1.2006.
    Args:
      q (string): the search term to use
      before (date): a date object. If not set, a random timestamp from at least a year ago will be generated.
    Return:
      a dict of {q, before, after}
    """
    if before:
      after = year_since(before)

    # generate a timewindow
    else:
      before = self.choose_random_date()
      after = self.year_since(before)

    iso_before = self.date_to_isoformat(before)
    iso_after = self.date_to_isoformat(after)
    search_params = {"q": q, "before": iso_before, "after": iso_after}
    print "Using timewindow: {} - {}".format(iso_after, iso_before)

    return search_params

  def choose_random_date(self):
    """Randomly choose a date between a year ago and 1.1.2006, (Yotube was founded on 14.2.2005).
    Return:
      a date object
    """
    # compute number of days since 1.1.2006
    delta = datetime.date.today() - datetime.date(2006, 1, 1)
    delta = delta.days

    # Randomly choose a day offset from 1.1.2006
    offset = random.randint(0, delta - 365)
    random_date = datetime.date(2006, 1, 1) + datetime.timedelta(days = offset)
    return random_date

  def year_since(self, start):
    """Compute the date 365 days before the given date.
    Arg:
    start (date): a date object
    Return:
      a datetime
    """
    return start - datetime.timedelta(days = 365)

  def date_to_isoformat(self, date):
    """Format a date object as RFC 3339 timestamp with 0s as time values.
    Arg:
        date (date): a date object
    Return:
      a formatted string
    """
    return date.isoformat() + "T00:00:00Z"


  #==============================================================================
  # Main =
  #=======
  def main(self, args):
    """Define procedures for each command line argument.
    TODO: Should this script even be runnable?
    Arg:
      args (list): a list of command line arguments passed to the script
    """

    # -q
    # Perform a sample search and  show results on stdout. Doesn't modify
    # links.json or search_terms.json, but doen't guarantee zero view items either.
    if args.q:
      search_params = self.format_search_params(args.q, args.random_window)  # format a dict of parameters as required by youtube_query()
      response = self.youtube_query(search_params)
      if not response:
        print "No results"

      else:
        # Get all items from the last page of results.
        for res in response["items"]:
          vid_id = res["id"]["videoId"]
          stats = self.get_stats(vid_id)
          views = int(stats["views"])

          title = res["snippet"]["title"]
          url = "https://www.youtube.com/watch?v=" + vid_id
          view_count = stats["views"]
          upload_date = stats["upload_date"]
          print title
          print url
          print "views:", views
          print "uploaded:", upload_date



#==============================================================================
if __name__ == "__main__":
  parser = argparse.ArgumentParser(description = "Search for and tweet Youtube videos with no or little views.")
  parser.add_argument("-q", help = "Perform a sample search on given search term. Prints the items with least views to stdout.", metavar = "search_term")
  parser.add_argument("--random-window", help = "Whether a randomized year long time window should be used with the -q switch.", action="store_true")
  args = parser.parse_args()
  #print args
